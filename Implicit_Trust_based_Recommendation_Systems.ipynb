{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Implicit Trust based recommendation system\n",
    "    developed by Priyanka Singhal\n",
    "'''\n",
    "import itertools\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 1: Load the Epinions Dataset. Pre-process dataset to select only relevant columns - item, user, stars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 188477 ; Columns: 6 \n",
      "\n",
      "First 4 rows of relevant columns only \n",
      "                                                item        user  stars\n",
      "0                 Minolta_QMS_PagePro_1250E_Printers      fgb59h      4\n",
      "1  Sony_VAIO_PCG_K45_P4_538_3_2GHz_1MB_L2_533MHz_...    bucho_ky      2\n",
      "2  Sony_VAIO_PCG_K45_P4_538_3_2GHz_1MB_L2_533MHz_...     redp944      4\n",
      "3              pr-Durabrand_CD-85_Personal_CD_Player  spongebag7      4\n"
     ]
    }
   ],
   "source": [
    "#Step 1: Load the dataset\n",
    "file_path = 'epinions_with_quotes.json'\n",
    "epinion_data = pd.read_json(file_path, lines=True)\n",
    "epinion_data.head(3)\n",
    "print('Rows:', epinion_data.shape[0], '; Columns:', epinion_data.shape[1], '\\n')\n",
    "\n",
    "# Select relevant columns (item, user, stars)\n",
    "epinion_data_slim = epinion_data[['item', 'user', 'stars']]\n",
    "print(\"First 4 rows of relevant columns only \")\n",
    "print(epinion_data_slim.head(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 2 - Pre-process dataset further to select training and test splits. We do an 80:20 split for training/test. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of tuples before dataset split: 188477\n",
      "Length of training set: 152000\n",
      "Length of test set: 36477\n"
     ]
    }
   ],
   "source": [
    "# Convert data to tuples of (item, user, rating) triplets\n",
    "dataset_tuples = [tuple(x) for x in epinion_data_slim.values]\n",
    "print(\"Total number of tuples before dataset split: {}\".format(len(dataset_tuples)))\n",
    "\n",
    "# Randomly shuffle dataset with fixed seed. Then split into train/test using 80:20 ratio\n",
    "random.Random(4).shuffle(dataset_tuples)\n",
    "train_data = dataset_tuples[:152000]\n",
    "test_data = dataset_tuples[152000:]\n",
    "\n",
    "# Print length of train and test dataset\n",
    "print(\"Length of training set: {}\".format(len(train_data)))\n",
    "print(\"Length of test set: {}\".format(len(test_data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 3 - Construct user2item and item2user dictionaries from training data. Also, retain rating for each value in both dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of entries in user2item: 98562\n",
      "Total number of entries in item2user: 37417\n",
      "Printing 5 random entries in user2item.. \n",
      "consumerdude\n",
      "{('cmhd-Accessories-All-Wireless_Optical_Mini_Mouse_PAUM005U', 1), ('pr-Dell_Axim_X5_400_MHz_Personal_Organizer', 3), ('nikon-coolpix-p310-light-field-camera', 5), ('logitech-wireless-touch-keyboard-k400-920003116', 5), ('pr-Digital_Cameras-Sony_DSC-P8_Digital_Camera', 1), ('Sony_Cyber_shot_DSC_T200_Digital_Camera_SNY13003', 4), ('Sony_DSC_P7_Digital_Camera_Digital_Cameras', 5), ('pr-RIM_BlackBerry_7100', 5)}\n",
      "ttdsgnr\n",
      "{('auto_Make-1998_Honda_CR_V', 5), ('auto_Make-1987_Suzuki_Samurai', 3), ('auto_Make-1990_Honda_Civic_2_Door', 5)}\n",
      "darobin\n",
      "{('elec_Portable_Audio-MD_Walkman_Sony_MZ_R-Sony_MZ-B3', 5), ('Dell_Adamo_XPS_Laptop_with_Intel_Core_2_Duo_Processor_Silver_AX3601GSL_PC_Notebook', 5), ('elec_Portable_Audio-MD_Walkman_Sony_MZ_R-Sony_MZ-R5ST', 5)}\n",
      "Chris_Billings\n",
      "{('5000202-lego-lord-of-the-rings-elrond-exclusive-minifigure', 4), ('Ultra_Pro_3_x_4_Toploaders_Card_Holder', 4), ('Funko-Lord-of-the-Rings-Gandalf-Plushies', 5), ('Hasbro_Star_Wars_The_Clone_Wars_R2_D2_w_Hidden_Gadgets_3_3_4_Action_Figure_epi', 4), ('G_I_Joe_The_Rise_of_Cobra_Single_Pack_Figure_Snake_Eyes_Ninja_Commando', 4), ('DC-Shoes-DC-Yepito-Beanie-Black-Lapis-One-Size', 5), ('LEGO_Collectible_Minifigure_Zombie_epi', 4), ('Indiana_Jones_Irina_Spalko_Kocs_Figure', 3), ('Mattel_2009_Hot_Wheels_037_190_Datsun_Bluebird_510_Copper_164', 3), ('Star_Wars_The_Vintage_Collection_2010_Boba_Fett_epi', 5), ('Halo_3_McFarlane_Odd_Pod_Stylized_Figure_Master_Chief_Assault_Rifle', 3), ('Mattel_Ghostbusters_Ray_Stantz_Blue_Lab_Coat_6_inch_action_figure_epi', 5), ('LEGO_Collectible_Minifigure_Forestman_epi', 4), ('LEGO_LEGO_Minifigure_Series_2_Explorer_epi', 4), ('Hasbro_Star_Wars_Vintage_Collection_Han_Solo_Echo_Base_Outfit_Action_Figure_epi', 4), ('LEGO_Collectible_Minifigure_Cowboy_epi', 4), ('LEGO_Collectible_Minifigure_Super_Wrestler_epi', 3), ('LEGO_30070_Toy_Story_3_Alien_Space_Ship_Toys_R_Us_Exclusive_epi', 4)}\n",
      "koral-soup\n",
      "{('Hasbro_Fur_Real_Friends_Collectible_Yellow_Duckling', 5), ('Mattel_Little_Mommy_Real_Loving_Baby_Doll', 4), ('pr-Printers_Hewlett_Packard_HP_PhotoSmart_1115_Personal_C8639AR_ABA', 5), ('hmgd-Blenders-Oster-Oster_Cube_Blenders_with_Plastic_Jar', 5), ('Easystore_Large_Slide', 3), ('Disguise_Disney_Princess_Princess_Cinderella_Deluxe_Costume_Dress', 5), ('Little_Tikes_Totsports_Easy_Score_Basketball_Set', 4), ('New_Baby_FURREAL_FRIENDS_Newborn_Pig_PIGLET_Fur_Real', 5), ('Logitech_Cordless_Optical_Mouse__Mousing_Devices_930616_0403_KIT', 5), ('LG_VX8300_Cellular_Phone', 5)}\n"
     ]
    }
   ],
   "source": [
    "# Construct user2item from training data\n",
    "user2item = {}\n",
    "for data_tuple in train_data:\n",
    "    if data_tuple[1] in user2item:\n",
    "        user2item[data_tuple[1]].add((data_tuple[0], data_tuple[2]))\n",
    "    else:\n",
    "        itemrating = set()\n",
    "        itemrating.add((data_tuple[0], data_tuple[2]))\n",
    "        user2item[data_tuple[1]] = itemrating\n",
    "\n",
    "# Construct item2user from training data\n",
    "item2user = {}\n",
    "for data_tuple in train_data:\n",
    "    if data_tuple[0] in item2user:\n",
    "        item2user[data_tuple[0]].add((data_tuple[1], data_tuple[2]))\n",
    "    else:\n",
    "        userrating = set()\n",
    "        userrating.add((data_tuple[1], data_tuple[2]))\n",
    "        item2user[data_tuple[0]] = userrating\n",
    "        \n",
    "print(\"Total number of entries in user2item: {}\".format(len(user2item)))\n",
    "print(\"Total number of entries in item2user: {}\".format(len(item2user)))\n",
    "print(\"Printing 5 random entries in user2item.. \")\n",
    "for i, val in enumerate(itertools.islice(user2item, 5)):\n",
    "    print(val)\n",
    "    print(user2item[val])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 4 - Approach 1 - Implicit trust. We will now write methods to compute implicit trust between users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.23529411764705882\n",
      "0.08519773513040674\n",
      "0.26665558577993353\n"
     ]
    }
   ],
   "source": [
    "# Fixed hyperparameters\n",
    "alpha = 0.4\n",
    "beta = 0.6\n",
    "sigma = 0.2\n",
    "\n",
    "\n",
    "def compute_ji(u1, u2, user2item, item2user):\n",
    "    \"\"\"\n",
    "    Compute Jaccard-index for user1 and user2\n",
    "    \"\"\"\n",
    "    # Get all items for u1    \n",
    "    u1_items = [tup[0] for tup in user2item[u1]]\n",
    "    \n",
    "    # For all u1 items, get all users wbo have rated it\n",
    "    u1_nbs = set()\n",
    "    for u1_item in u1_items:\n",
    "        # Get all users who have rated item\n",
    "        users = [tup[0] for tup in item2user[u1_item]]\n",
    "        # Extend u1_nbs\n",
    "        u1_nbs.update(users)\n",
    "    \n",
    "    # Get all items for u2    \n",
    "    u2_items = [tup[0] for tup in user2item[u2]]\n",
    "    \n",
    "    # For all u2 items, get all users wbo have rated it\n",
    "    u2_nbs = set()\n",
    "    for u2_item in u2_items:\n",
    "        # Get all users who have rated item\n",
    "        users = [tup[0] for tup in item2user[u2_item]]\n",
    "        # Extend u1_nbs\n",
    "        u2_nbs.update(users)    \n",
    "\n",
    "    common_users = u1_nbs.intersection(u2_nbs)\n",
    "    union_users = u1_nbs.union(u2_nbs)\n",
    "   \n",
    "    # Return ji\n",
    "    return len(common_users)/ (1.0 * len(union_users))\n",
    "    \n",
    "def calc_d(i1, sigma, item2user):\n",
    "    \"\"\"\n",
    "    Calculate item popularity index D(i) for item i\n",
    "    \"\"\"\n",
    "    # Get number of user who have rated item\n",
    "    degree_i1 = len(item2user[i1])\n",
    "    \n",
    "    # return D(i)\n",
    "    return (2.0 / (1 + np.exp(2**sigma - degree_i1**sigma))) - 1.0\n",
    "\n",
    "# Unit test for compute_ji. Expected output is 0.2352941176\n",
    "print(compute_ji('pyros7', 'tarsyn', user2item, item2user))\n",
    "\n",
    "# Unit test for calc_d. Expected output is 0.08519773513\n",
    "print(calc_d('pr-Sony_KV_36FS12__Standard_Televisions', sigma, item2user))\n",
    "\n",
    "# Unit test for calc_d. Expected output is 0.266655586\n",
    "print(calc_d('auto_Make-2001_Pontiac_Firebird', sigma, item2user))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9148022648695933\n"
     ]
    }
   ],
   "source": [
    "def calc_common_item_popularity(u1, u2, sigma, user2item, item2user):\n",
    "    \"\"\"\n",
    "    Calculate common item popularity for user1 and user2\n",
    "    \"\"\"\n",
    "    # Get all items for u1\n",
    "    u1_items = set([tup[0] for tup in user2item[u1]])\n",
    "\n",
    "    # Get all items for u2\n",
    "    u2_items = set([tup[0] for tup in user2item[u2]])\n",
    "\n",
    "    # For common items, calculate D(i)\n",
    "    common_items = u1_items.intersection(u2_items)\n",
    "    if not common_items or len(common_items) == 0:\n",
    "        return 0.0\n",
    "    \n",
    "    # Handling edge cases\n",
    "    sum_d = 0.0\n",
    "    for common_item in common_items:\n",
    "        sum_d = sum_d + calc_d(common_item, sigma, item2user)\n",
    "    \n",
    "    return 1.0  - (sum_d)/(len(common_items))\n",
    "\n",
    "# Unit test for calc_common_item_popularity. Expected output is 0.9148022648695933\n",
    "print(calc_common_item_popularity('pyros7', 'tarsyn', sigma, user2item, item2user))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6429990059805795\n"
     ]
    }
   ],
   "source": [
    "def compute_implicit_trust(u1, u2, alpha, beta, sigma, user2item, item2user):\n",
    "    # Step 1 - Compute Jaccard Index\n",
    "    ji = compute_ji(u1, u2, user2item, item2user)\n",
    "    #  print(\"ji \".format(ji))\n",
    "    # Step 2 - Compute common similarity\n",
    "    com_sim = calc_common_item_popularity(u1, u2, sigma, user2item, item2user)\n",
    "    \n",
    "    # Step 3 - Combine both\n",
    "    return alpha * ji + beta * com_sim\n",
    "\n",
    "# Unit test for compute_implicit_trust. Expected output is 0.642999006\n",
    "print(compute_implicit_trust('pyros7', 'tarsyn', alpha, beta, sigma, user2item, item2user))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 5 - Before predicting ratings on the test set, define common methods for error/result calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Methods for Mean Absolute Error (MAE) and Mean Squared Error (MSE)\n",
    "def calculate_mae(result_set):\n",
    "    mae = 0.0\n",
    "    for result in result_set:\n",
    "        mae = mae + np.abs(result[0] - result[1])\n",
    "    return mae / len(result_set)\n",
    "\n",
    "def calculate_rmse(result_set):\n",
    "    rmse = 0.0\n",
    "    for result in result_set:\n",
    "        rmse = rmse + (result[0] - result[1]) * (result[0] - result[1])\n",
    "    return rmse / len(result_set)\n",
    "\n",
    "def run_inference_on_test_set(test_data, user2item, item2user, inference_method,alpha, beta, sigma):\n",
    "    \"\"\"\n",
    "    Run infereence on test set, based on inference_method (function parameter)\n",
    "    \"\"\"\n",
    "    # Create counters for actual inference, user-cold start and item-cold start\n",
    "    actual_inference_count = 0\n",
    "    user_cold_start_cnt = 0\n",
    "    item_cold_start_cnt = 0\n",
    "    \n",
    "    # Run inference on test set\n",
    "    result_set = []\n",
    "    for idx, test_sample in enumerate(test_data): \n",
    "        if not test_sample[1] in user2item:\n",
    "            user_cold_start_cnt += 1\n",
    "            continue\n",
    "        if not test_sample[0] in item2user:\n",
    "            item_cold_start_cnt += 1\n",
    "            continue\n",
    "\n",
    "        ground_truth_rating = test_sample[2]\n",
    "        predicted_rating = inference_method(test_sample[1], test_sample[0], alpha, beta, sigma, user2item, item2user)\n",
    "        if predicted_rating == 0.0:\n",
    "            # Skip since user might not have anything in common with other raters of item\n",
    "            continue        \n",
    "        result_set.append((ground_truth_rating, predicted_rating))\n",
    "        actual_inference_count += 1\n",
    "    # Print stats\n",
    "    print(actual_inference_count)\n",
    "    print(\"Item cold start count : {}\".format(item_cold_start_cnt))\n",
    "    print(\"User cold start count : {}\".format(user_cold_start_cnt))\n",
    "\n",
    "    print(\"Coverage : {}\".format(actual_inference_count / (1.0 * len(test_data)) ))\n",
    "    print(\"Mean Absolute Error : {}\".format(calculate_mae(result_set)))\n",
    "    print(\"RMSE : {}\".format(calculate_rmse(result_set)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 6 - Different methods to predict test ratings\n",
    "\n",
    "# STEP 6.1 - Method 1 - Simple trust-based mean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4088\n",
      "Item cold start count : 3268\n",
      "User cold start count : 18378\n",
      "Coverage : 0.11207061984264056\n",
      "Mean Absolute Error : 0.9513092351459769\n",
      "RMSE : 1.817979469041858\n"
     ]
    }
   ],
   "source": [
    "def calc_trust_based_mean_rating(u, i, alpha, beta, sigma, user2item, item2user):\n",
    "    \"\"\"\n",
    "    Calculate trust-based mean rating on test set\n",
    "    \"\"\"\n",
    "    # Get all users who have rated item\n",
    "    users_and_ratings = [tup for tup in item2user[i]]\n",
    "    \n",
    "    # For each user, calculate trust with test user u\n",
    "    sum_of_num = 0.0\n",
    "    sum_of_den = 0.0\n",
    "    for user_and_rating in users_and_ratings:\n",
    "        trust_uv = compute_implicit_trust(u, user_and_rating[0], alpha, beta, sigma, user2item, item2user)\n",
    "        sum_of_num = sum_of_num + trust_uv * user_and_rating[1]\n",
    "        sum_of_den = sum_of_den + trust_uv\n",
    "    if sum_of_den == 0.0:\n",
    "        return 0.0\n",
    "    return sum_of_num / sum_of_den\n",
    "\n",
    "# Run inference on test set using trust-based mean rating\n",
    "run_inference_on_test_set(test_data, user2item, item2user, calc_trust_based_mean_rating, alpha, beta, sigma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 6.2 - Method 2 - Trust-based collaborative filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4088\n",
      "Item cold start count : 3268\n",
      "User cold start count : 18378\n",
      "Coverage : 0.11207061984264056\n",
      "Mean Absolute Error : 1.0613721153161506\n",
      "RMSE : 2.0063752735202836\n"
     ]
    }
   ],
   "source": [
    "def calc_average_user_rating(u, user2item):\n",
    "    if not u in user2item:\n",
    "        return 0.0\n",
    "    return np.average([tup[1] for tup in user2item[u]])\n",
    "\n",
    "\n",
    "def calc_trust_based_collab_filtering(u, i, alpha, beta, sigma, user2item, item2user):\n",
    "    \"\"\"\n",
    "    Calculate trust-based collaborative filtering rating on test set\n",
    "    \"\"\"\n",
    "    # Get all users who have rated item\n",
    "    users_and_ratings = [tup for tup in item2user[i]]\n",
    "    \n",
    "    # For each user, calculate trust with test user u\n",
    "    sum_of_num = 0.0\n",
    "    sum_of_den = 0.0\n",
    "    for user_and_rating in users_and_ratings:\n",
    "        trust_uv = compute_implicit_trust(u, user_and_rating[0], alpha, beta, sigma, user2item, item2user)\n",
    "        sum_of_num = sum_of_num + trust_uv * (user_and_rating[1] - calc_average_user_rating(user_and_rating[0], user2item))\n",
    "        sum_of_den = sum_of_den + trust_uv\n",
    "    # Return 0 if no user has rated item\n",
    "    if sum_of_den == 0.0:\n",
    "        return 0.0\n",
    "    return calc_average_user_rating(u, user2item) + (sum_of_num/sum_of_den)\n",
    "\n",
    "# Run inference on test set using trust-based collaborative filtreing\n",
    "run_inference_on_test_set(test_data, user2item, item2user, calc_trust_based_collab_filtering, alpha, beta, sigma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 6.3 - Method 3 - Trust-filtered mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4088\n",
      "Item cold start count : 3268\n",
      "User cold start count : 18378\n",
      "Coverage : 0.11207061984264056\n",
      "Mean Absolute Error : 0.9376778610565589\n",
      "RMSE : 1.7134297967067953\n"
     ]
    }
   ],
   "source": [
    "def calc_trust_filtered_mean_rating(u, i, alpha, beta, sigma, user2item, item2user):\n",
    "    \"\"\"\n",
    "    Calculate trust-filterd mean rating on tst set. We filter for trust > 0\n",
    "    \"\"\"\n",
    "    # Get all users who have rated item\n",
    "    users_and_ratings = [tup for tup in item2user[i]]\n",
    "    \n",
    "    # For each user, calculate trust with test user u\n",
    "    sum_of_num = 0.0\n",
    "    trust_cnt = 0\n",
    "    for user_and_rating in users_and_ratings:\n",
    "        trust_uv = compute_implicit_trust(u, user_and_rating[0], alpha, beta, sigma, user2item, item2user)\n",
    "        if trust_uv > 0.0:\n",
    "            sum_of_num = sum_of_num + user_and_rating[1]\n",
    "            trust_cnt += 1\n",
    "    if trust_cnt == 0:\n",
    "        return 0.0\n",
    "    return sum_of_num / (1.0 * trust_cnt)\n",
    "\n",
    "# Run inference on test set using trust-filtered mean\n",
    "run_inference_on_test_set(test_data, user2item, item2user, calc_trust_filtered_mean_rating, alpha, beta, sigma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 7 - We notice that the coverage is low for the implicit approach. The reason for this that many users have only 1-2 ratings in the dataset. Thus, these users fall in the cold-start case\n",
    "\n",
    "# We now focus on filtering the dataset for users with >=4 items rated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a user2item dictionary over the entire dataset, and not just training set\n",
    "user2item_full = {}\n",
    "for data_tuple in dataset_tuples:\n",
    "    if data_tuple[1] in user2item_full:\n",
    "        user2item_full[data_tuple[1]].add((data_tuple[0], data_tuple[2]))\n",
    "    else:\n",
    "        itemrating = set()\n",
    "        itemrating.add((data_tuple[0], data_tuple[2]))\n",
    "        user2item_full[data_tuple[1]] = itemrating\n",
    "        \n",
    "filtered_dataset_tuples = [data_tuple for data_tuple in dataset_tuples if len(user2item_full[data_tuple[1]]) >= 4]\n",
    "\n",
    "print(\"Number of data points in original dataset tuples: {}\".format(len(dataset_tuples)))\n",
    "print(\"Number of data points in filtered dataset tuples: {}\".format(len(filtered_dataset_tuples)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 8 - Split filtered dataset in train/test using 80:20 split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly shuffle dataset with fixed seed. Then split into train/test using 80:20 ratio\n",
    "random.Random(4).shuffle(filtered_dataset_tuples)\n",
    "filtered_train_data = filtered_dataset_tuples[:43600]\n",
    "filtered_test_data = filtered_dataset_tuples[43600:]\n",
    "\n",
    "# Print length of train and test dataset\n",
    "print(\"Length of filtered training set: {}\".format(len(filtered_train_data)))\n",
    "print(\"Length of filtered test set: {}\".format(len(filtered_test_data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 9 - Construct user2item and item2user dictionaries from filtered training data. Also, retain rating for each value in both dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct user2item from training data\n",
    "filtered_user2item = {}\n",
    "for data_tuple in filtered_train_data:\n",
    "    if data_tuple[1] in filtered_user2item:\n",
    "        filtered_user2item[data_tuple[1]].add((data_tuple[0], data_tuple[2]))\n",
    "    else:\n",
    "        itemrating = set()\n",
    "        itemrating.add((data_tuple[0], data_tuple[2]))\n",
    "        filtered_user2item[data_tuple[1]] = itemrating\n",
    "\n",
    "# Construct item2user from training data\n",
    "filtered_item2user = {}\n",
    "for data_tuple in filtered_train_data:\n",
    "    if data_tuple[0] in filtered_item2user:\n",
    "        filtered_item2user[data_tuple[0]].add((data_tuple[1], data_tuple[2]))\n",
    "    else:\n",
    "        userrating = set()\n",
    "        userrating.add((data_tuple[1], data_tuple[2]))\n",
    "        filtered_item2user[data_tuple[0]] = userrating\n",
    "        \n",
    "print(\"Total number of entries in filtered_user2item: {}\".format(len(filtered_user2item)))\n",
    "print(\"Total number of entries in filtered_item2user: {}\".format(len(filtered_item2user)))\n",
    "print(\"Printing 5 random entries in filtered_user2item.. \")\n",
    "for i, val in enumerate(itertools.islice(filtered_user2item, 5)):\n",
    "    print(val)\n",
    "    print(filtered_user2item[val])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 10 - Run inference using all 3 methods on the filtered dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run inference on test set using trust-based mean rating\n",
    "print(\"Running inference on filtered test set using trust-based mean rating\")\n",
    "run_inference_on_test_set(filtered_test_data, filtered_user2item, filtered_item2user, calc_trust_based_mean_rating, alpha, beta, sigma)\n",
    "\n",
    "# Run inference on test set using trust-based collaborative filtering\n",
    "print(\"Running inference on filtered test set using trust-based collaborative filtering\")\n",
    "run_inference_on_test_set(filtered_test_data, filtered_user2item, filtered_item2user, calc_trust_based_collab_filtering, alpha, beta, sigma)\n",
    "\n",
    "# Run inference on test set using trust-filtered mean\n",
    "print(\"Running inference on filtered test set using trust-filtered mean rating\")\n",
    "run_inference_on_test_set(filtered_test_data, filtered_user2item, filtered_item2user, calc_trust_filtered_mean_rating, alpha, beta, sigma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 11 - Recommend top N item for 3 users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17578\n",
      "Top 10 for ptiemann\n",
      "('auto_Make-1991_Honda_Accord_Sedan', 5.0)\n",
      "('Nokia_6161_Cellular_Phone', 5.0)\n",
      "('pr-Sony_KV_40XBR800__Standard_Televisions', 5.0)\n",
      "('elec_Cameras-Digital_KodakDCC-Kodak_DC-290', 5.0)\n",
      "('pr-Apple_iPod_15GB_MAC_MP3_Player', 5.0)\n",
      "('pr-PDAs_Sony_CLIE_PEG_T665C_Handheld_PEG_T665C_U', 5.0)\n",
      "('pr-Sony_KV_20FS12__Standard_Televisions', 5.0)\n",
      "('cmsw-ISP-All-Road_Runner__includes_MediaOne_', 5.0)\n",
      "('Canon_Pixma_MP500_Printer', 5.0)\n",
      "('cmhd-MousingDevices-All-Microsoft_IntelliMouse_Explorer', 5.0)\n",
      "Top 10 for kristinafh\n",
      "('elec_Cameras-Point_And_Shoot_OlympusStyluss-Olympus_Stylus_Epic', 5.0)\n",
      "('hmgd-Moving_Services-All-Penske_Moving_Service', 5.0)\n",
      "('auto_Make-2003_Mazda_Mazda6', 5.0)\n",
      "('Apple_MB062LL_A_2_16GHZ_MACBOOK_13_3_2_16_GHz_Intel_Core_2_Duo_MacBook_Laptop_PC_Notebook', 5.0)\n",
      "('Canon_SELPHY_CP740_CARD_PHOTO_PRINTER_2_0_LCD_PICTBRIDGE_DIRECT_PRINT_UK_2094B008AA_Printers_Ph', 5.0)\n",
      "('pr-Fuji_FinePix_S3_Pro_Digital_Camera', 5.0)\n",
      "('LG_Large_Appliances_Washers_Front_Load', 5.0)\n",
      "('Verizon_Wireless_RIM_Blackberry_8703e', 5.0)\n",
      "('auto_Make-1991_Oldsmobile_Cutlass_Ciera', 5.0)\n",
      "('2008_Toyota_4Runner', 5.0)\n",
      "Top 10 for spongebag7\n",
      "('elec_Cameras-Point_And_Shoot_OlympusStyluss-Olympus_Stylus_Epic', 5.0)\n",
      "('auto_Make-2003_Mazda_Mazda6', 5.0)\n",
      "('Emerson_EWL3706_Television', 5.0)\n",
      "('Apple_MB062LL_A_2_16GHZ_MACBOOK_13_3_2_16_GHz_Intel_Core_2_Duo_MacBook_Laptop_PC_Notebook', 5.0)\n",
      "('pr-Gateway_300_X_300X_PC_Desktop', 5.0)\n",
      "('Canon_SELPHY_CP740_CARD_PHOTO_PRINTER_2_0_LCD_PICTBRIDGE_DIRECT_PRINT_UK_2094B008AA_Printers_Ph', 5.0)\n",
      "('Microsoft_Trackball_Optical__Mousing_Devices_D67_00001', 5.0)\n",
      "('pr-Panasonic_DMR-E85H_DVD', 5.0)\n",
      "('Samsung_Yepp_YP_T9_4_GB_MP3_Player', 5.0)\n",
      "('Verizon_Wireless_RIM_Blackberry_8703e', 5.0)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None, None, None, None, None, None, None, None]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_items = set([tup[0] for tup in test_data])\n",
    "print(len(test_items))\n",
    "\n",
    "user1_test_data = [(test_item, 'ptiemann') for test_item in test_items]\n",
    "user2_test_data = [(test_item, 'kristinafh') for test_item in test_items]\n",
    "user3_test_data = [(test_item, 'spongebag7') for test_item in test_items]\n",
    "\n",
    "def get_top_n_predictions_on_test_set(user_test_data, n, user2item, item2user, alpha, beta, sigma, calc_trust_filtered_mean_rating):\n",
    "    result_set = []\n",
    "    for idx, test_sample in enumerate(user_test_data): \n",
    "        if not test_sample[1] in user2item:\n",
    "            continue\n",
    "        if not test_sample[0] in item2user:\n",
    "            continue\n",
    "        predicted_rating = calc_trust_filtered_mean_rating(test_sample[1], test_sample[0], alpha, beta, sigma, user2item, item2user)\n",
    "        if predicted_rating == 0.0:\n",
    "            # Skip since user might not have anything in common with other raters of item\n",
    "            continue        \n",
    "        result_set.append((test_sample[0], predicted_rating))\n",
    "    sorted_result_set = sorted(result_set,key=itemgetter(1), reverse=True)\n",
    "    return sorted_result_set[:n]\n",
    "\n",
    "print(\"Top 10 for ptiemann\")\n",
    "[print(result) for result in get_top_n_predictions_on_test_set(user1_test_data, 10, user2item, item2user, alpha, beta, sigma, calc_trust_filtered_mean_rating)]\n",
    "print(\"Top 10 for kristinafh\")\n",
    "[print(result) for result in get_top_n_predictions_on_test_set(user2_test_data, 10, user2item, item2user, alpha, beta, sigma, calc_trust_filtered_mean_rating)]\n",
    "print(\"Top 10 for spongebag7\")\n",
    "[print(result) for result in get_top_n_predictions_on_test_set(user3_test_data, 10, user2item, item2user, alpha, beta, sigma, calc_trust_filtered_mean_rating)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
