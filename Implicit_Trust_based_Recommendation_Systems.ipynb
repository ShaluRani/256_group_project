{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Implicit Trust based recommendation system\n",
    "    developed by Priyanka Singhal\n",
    "'''\n",
    "import itertools\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 1: Load the Epinions Dataset. Pre-process dataset to select only relevant columns - item, user, stars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 188477 ; Columns: 6 \n",
      "\n",
      "First 4 rows of relevant columns only \n",
      "                                                item        user  stars\n",
      "0                 Minolta_QMS_PagePro_1250E_Printers      fgb59h      4\n",
      "1  Sony_VAIO_PCG_K45_P4_538_3_2GHz_1MB_L2_533MHz_...    bucho_ky      2\n",
      "2  Sony_VAIO_PCG_K45_P4_538_3_2GHz_1MB_L2_533MHz_...     redp944      4\n",
      "3              pr-Durabrand_CD-85_Personal_CD_Player  spongebag7      4\n"
     ]
    }
   ],
   "source": [
    "#Step 1: Load the dataset\n",
    "file_path = 'epinions_with_quotes.json'\n",
    "epinion_data = pd.read_json(file_path, lines=True)\n",
    "epinion_data.head(3)\n",
    "print('Rows:', epinion_data.shape[0], '; Columns:', epinion_data.shape[1], '\\n')\n",
    "\n",
    "# Select relevant columns (item, user, stars)\n",
    "epinion_data_slim = epinion_data[['item', 'user', 'stars']]\n",
    "print(\"First 4 rows of relevant columns only \")\n",
    "print(epinion_data_slim.head(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 2 - Pre-process dataset further to select training and test splits. We do an 80:20 split for training/test. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of tuples before dataset split: 188477\n",
      "Length of training set: 152000\n",
      "Length of test set: 36477\n"
     ]
    }
   ],
   "source": [
    "# Convert data to tuples of (item, user, rating) triplets\n",
    "dataset_tuples = [tuple(x) for x in epinion_data_slim.values]\n",
    "print(\"Total number of tuples before dataset split: {}\".format(len(dataset_tuples)))\n",
    "\n",
    "# Randomly shuffle dataset with fixed seed. Then split into train/test using 80:20 ratio\n",
    "random.Random(4).shuffle(dataset_tuples)\n",
    "train_data = dataset_tuples[:152000]\n",
    "test_data = dataset_tuples[152000:]\n",
    "\n",
    "# Print length of train and test dataset\n",
    "print(\"Length of training set: {}\".format(len(train_data)))\n",
    "print(\"Length of test set: {}\".format(len(test_data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 3 - Construct user2item and item2user dictionaries from training data. Also, retain rating for each value in both dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of entries in user2item: 98562\n",
      "Total number of entries in item2user: 37417\n",
      "Printing 5 random entries in user2item.. \n",
      "consumerdude\n",
      "{('pr-Digital_Cameras-Sony_DSC-P8_Digital_Camera', 1), ('cmhd-Accessories-All-Wireless_Optical_Mini_Mouse_PAUM005U', 1), ('Sony_DSC_P7_Digital_Camera_Digital_Cameras', 5), ('logitech-wireless-touch-keyboard-k400-920003116', 5), ('Sony_Cyber_shot_DSC_T200_Digital_Camera_SNY13003', 4), ('pr-Dell_Axim_X5_400_MHz_Personal_Organizer', 3), ('pr-RIM_BlackBerry_7100', 5), ('nikon-coolpix-p310-light-field-camera', 5)}\n",
      "ttdsgnr\n",
      "{('auto_Make-1987_Suzuki_Samurai', 3), ('auto_Make-1998_Honda_CR_V', 5), ('auto_Make-1990_Honda_Civic_2_Door', 5)}\n",
      "darobin\n",
      "{('elec_Portable_Audio-MD_Walkman_Sony_MZ_R-Sony_MZ-B3', 5), ('elec_Portable_Audio-MD_Walkman_Sony_MZ_R-Sony_MZ-R5ST', 5), ('Dell_Adamo_XPS_Laptop_with_Intel_Core_2_Duo_Processor_Silver_AX3601GSL_PC_Notebook', 5)}\n",
      "Chris_Billings\n",
      "{('LEGO_Collectible_Minifigure_Zombie_epi', 4), ('Hasbro_Star_Wars_The_Clone_Wars_R2_D2_w_Hidden_Gadgets_3_3_4_Action_Figure_epi', 4), ('LEGO_Collectible_Minifigure_Super_Wrestler_epi', 3), ('Funko-Lord-of-the-Rings-Gandalf-Plushies', 5), ('Indiana_Jones_Irina_Spalko_Kocs_Figure', 3), ('LEGO_LEGO_Minifigure_Series_2_Explorer_epi', 4), ('5000202-lego-lord-of-the-rings-elrond-exclusive-minifigure', 4), ('Mattel_Ghostbusters_Ray_Stantz_Blue_Lab_Coat_6_inch_action_figure_epi', 5), ('DC-Shoes-DC-Yepito-Beanie-Black-Lapis-One-Size', 5), ('LEGO_Collectible_Minifigure_Cowboy_epi', 4), ('LEGO_Collectible_Minifigure_Forestman_epi', 4), ('Mattel_2009_Hot_Wheels_037_190_Datsun_Bluebird_510_Copper_164', 3), ('Star_Wars_The_Vintage_Collection_2010_Boba_Fett_epi', 5), ('LEGO_30070_Toy_Story_3_Alien_Space_Ship_Toys_R_Us_Exclusive_epi', 4), ('Halo_3_McFarlane_Odd_Pod_Stylized_Figure_Master_Chief_Assault_Rifle', 3), ('G_I_Joe_The_Rise_of_Cobra_Single_Pack_Figure_Snake_Eyes_Ninja_Commando', 4), ('Hasbro_Star_Wars_Vintage_Collection_Han_Solo_Echo_Base_Outfit_Action_Figure_epi', 4), ('Ultra_Pro_3_x_4_Toploaders_Card_Holder', 4)}\n",
      "koral-soup\n",
      "{('Easystore_Large_Slide', 3), ('pr-Printers_Hewlett_Packard_HP_PhotoSmart_1115_Personal_C8639AR_ABA', 5), ('Mattel_Little_Mommy_Real_Loving_Baby_Doll', 4), ('Disguise_Disney_Princess_Princess_Cinderella_Deluxe_Costume_Dress', 5), ('Little_Tikes_Totsports_Easy_Score_Basketball_Set', 4), ('Logitech_Cordless_Optical_Mouse__Mousing_Devices_930616_0403_KIT', 5), ('New_Baby_FURREAL_FRIENDS_Newborn_Pig_PIGLET_Fur_Real', 5), ('Hasbro_Fur_Real_Friends_Collectible_Yellow_Duckling', 5), ('hmgd-Blenders-Oster-Oster_Cube_Blenders_with_Plastic_Jar', 5), ('LG_VX8300_Cellular_Phone', 5)}\n"
     ]
    }
   ],
   "source": [
    "# Construct user2item from training data\n",
    "user2item = {}\n",
    "for data_tuple in train_data:\n",
    "    if data_tuple[1] in user2item:\n",
    "        user2item[data_tuple[1]].add((data_tuple[0], data_tuple[2]))\n",
    "    else:\n",
    "        itemrating = set()\n",
    "        itemrating.add((data_tuple[0], data_tuple[2]))\n",
    "        user2item[data_tuple[1]] = itemrating\n",
    "\n",
    "# Construct item2user from training data\n",
    "item2user = {}\n",
    "for data_tuple in train_data:\n",
    "    if data_tuple[0] in item2user:\n",
    "        item2user[data_tuple[0]].add((data_tuple[1], data_tuple[2]))\n",
    "    else:\n",
    "        userrating = set()\n",
    "        userrating.add((data_tuple[1], data_tuple[2]))\n",
    "        item2user[data_tuple[0]] = userrating\n",
    "        \n",
    "print(\"Total number of entries in user2item: {}\".format(len(user2item)))\n",
    "print(\"Total number of entries in item2user: {}\".format(len(item2user)))\n",
    "print(\"Printing 5 random entries in user2item.. \")\n",
    "for i, val in enumerate(itertools.islice(user2item, 5)):\n",
    "    print(val)\n",
    "    print(user2item[val])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 4 - Approach 1 - Implicit trust. We will now write methods to compute implicit trust between users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.23529411764705882\n",
      "0.08519773513040674\n",
      "0.26665558577993353\n"
     ]
    }
   ],
   "source": [
    "# Fixed hyperparameters\n",
    "alpha = 0.4\n",
    "beta = 0.6\n",
    "sigma = 0.2\n",
    "\n",
    "\n",
    "def compute_ji(u1, u2, user2item, item2user):\n",
    "    \"\"\"\n",
    "    Compute Jaccard-index for user1 and user2\n",
    "    \"\"\"\n",
    "    # Get all items for u1    \n",
    "    u1_items = [tup[0] for tup in user2item[u1]]\n",
    "    \n",
    "    # For all u1 items, get all users wbo have rated it\n",
    "    u1_nbs = set()\n",
    "    for u1_item in u1_items:\n",
    "        # Get all users who have rated item\n",
    "        users = [tup[0] for tup in item2user[u1_item]]\n",
    "        # Extend u1_nbs\n",
    "        u1_nbs.update(users)\n",
    "    \n",
    "    # Get all items for u2    \n",
    "    u2_items = [tup[0] for tup in user2item[u2]]\n",
    "    \n",
    "    # For all u2 items, get all users wbo have rated it\n",
    "    u2_nbs = set()\n",
    "    for u2_item in u2_items:\n",
    "        # Get all users who have rated item\n",
    "        users = [tup[0] for tup in item2user[u2_item]]\n",
    "        # Extend u1_nbs\n",
    "        u2_nbs.update(users)    \n",
    "\n",
    "    common_users = u1_nbs.intersection(u2_nbs)\n",
    "    union_users = u1_nbs.union(u2_nbs)\n",
    "   \n",
    "    # Return ji\n",
    "    return len(common_users)/ (1.0 * len(union_users))\n",
    "    \n",
    "def calc_d(i1, sigma, item2user):\n",
    "    \"\"\"\n",
    "    Calculate item popularity index D(i) for item i\n",
    "    \"\"\"\n",
    "    # Get number of user who have rated item\n",
    "    degree_i1 = len(item2user[i1])\n",
    "    \n",
    "    # return D(i)\n",
    "    return (2.0 / (1 + np.exp(2**sigma - degree_i1**sigma))) - 1.0\n",
    "\n",
    "# Unit test for compute_ji. Expected output is 0.2352941176\n",
    "print(compute_ji('pyros7', 'tarsyn', user2item, item2user))\n",
    "\n",
    "# Unit test for calc_d. Expected output is 0.08519773513\n",
    "print(calc_d('pr-Sony_KV_36FS12__Standard_Televisions', sigma, item2user))\n",
    "\n",
    "# Unit test for calc_d. Expected output is 0.266655586\n",
    "print(calc_d('auto_Make-2001_Pontiac_Firebird', sigma, item2user))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9148022648695933\n"
     ]
    }
   ],
   "source": [
    "def calc_common_item_popularity(u1, u2, sigma, user2item, item2user):\n",
    "    \"\"\"\n",
    "    Calculate common item popularity for user1 and user2\n",
    "    \"\"\"\n",
    "    # Get all items for u1\n",
    "    u1_items = set([tup[0] for tup in user2item[u1]])\n",
    "\n",
    "    # Get all items for u2\n",
    "    u2_items = set([tup[0] for tup in user2item[u2]])\n",
    "\n",
    "    # For common items, calculate D(i)\n",
    "    common_items = u1_items.intersection(u2_items)\n",
    "    if not common_items or len(common_items) == 0:\n",
    "        return 0.0\n",
    "    \n",
    "    # Handling edge cases\n",
    "    sum_d = 0.0\n",
    "    for common_item in common_items:\n",
    "        sum_d = sum_d + calc_d(common_item, sigma, item2user)\n",
    "    \n",
    "    return 1.0  - (sum_d)/(len(common_items))\n",
    "\n",
    "# Unit test for calc_common_item_popularity. Expected output is 0.9148022648695933\n",
    "print(calc_common_item_popularity('pyros7', 'tarsyn', sigma, user2item, item2user))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6429990059805795\n"
     ]
    }
   ],
   "source": [
    "def compute_implicit_trust(u1, u2, alpha, beta, sigma, user2item, item2user):\n",
    "    # Step 1 - Compute Jaccard Index\n",
    "    ji = compute_ji(u1, u2, user2item, item2user)\n",
    "    #  print(\"ji \".format(ji))\n",
    "    # Step 2 - Compute common similarity\n",
    "    com_sim = calc_common_item_popularity(u1, u2, sigma, user2item, item2user)\n",
    "    \n",
    "    # Step 3 - Combine both\n",
    "    return alpha * ji + beta * com_sim\n",
    "\n",
    "# Unit test for compute_implicit_trust. Expected output is 0.642999006\n",
    "print(compute_implicit_trust('pyros7', 'tarsyn', alpha, beta, sigma, user2item, item2user))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 5 - Before predicting ratings on the test set, define common methods for error/result calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Methods for Mean Absolute Error (MAE) and Mean Squared Error (MSE)\n",
    "def calculate_mae(result_set):\n",
    "    mae = 0.0\n",
    "    for result in result_set:\n",
    "        mae = mae + np.abs(result[0] - result[1])\n",
    "    return mae / len(result_set)\n",
    "\n",
    "def calculate_rmse(result_set):\n",
    "    rmse = 0.0\n",
    "    for result in result_set:\n",
    "        rmse = rmse + (result[0] - result[1]) * (result[0] - result[1])\n",
    "    return rmse / len(result_set)\n",
    "\n",
    "def run_inference_on_test_set(test_data, user2item, item2user, inference_method,alpha, beta, sigma):\n",
    "    \"\"\"\n",
    "    Run infereence on test set, based on inference_method (function parameter)\n",
    "    \"\"\"\n",
    "    # Create counters for actual inference, user-cold start and item-cold start\n",
    "    actual_inference_count = 0\n",
    "    user_cold_start_cnt = 0\n",
    "    item_cold_start_cnt = 0\n",
    "    \n",
    "    # Run inference on test set\n",
    "    result_set = []\n",
    "    for idx, test_sample in enumerate(test_data): \n",
    "        if not test_sample[1] in user2item:\n",
    "            user_cold_start_cnt += 1\n",
    "            continue\n",
    "        if not test_sample[0] in item2user:\n",
    "            item_cold_start_cnt += 1\n",
    "            continue\n",
    "\n",
    "        ground_truth_rating = test_sample[2]\n",
    "        predicted_rating = inference_method(test_sample[1], test_sample[0], alpha, beta, sigma, user2item, item2user)\n",
    "        if predicted_rating == 0.0:\n",
    "            # Skip since user might not have anything in common with other raters of item\n",
    "            continue        \n",
    "        result_set.append((ground_truth_rating, predicted_rating))\n",
    "        actual_inference_count += 1\n",
    "    # Print stats\n",
    "    print(actual_inference_count)\n",
    "    print(\"Item cold start count : {}\".format(item_cold_start_cnt))\n",
    "    print(\"User cold start count : {}\".format(user_cold_start_cnt))\n",
    "\n",
    "    print(\"Coverage : {}\".format(actual_inference_count / (1.0 * len(test_data)) ))\n",
    "    print(\"Mean Absolute Error : {}\".format(calculate_mae(result_set)))\n",
    "    print(\"RMSE : {}\".format(calculate_rmse(result_set)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 6 - Different methods to predict test ratings\n",
    "\n",
    "# STEP 6.1 - Method 1 - Simple trust-based mean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4088\n",
      "Item cold start count : 3268\n",
      "User cold start count : 18378\n",
      "Coverage : 0.11207061984264056\n",
      "Mean Absolute Error : 0.9513092351459769\n",
      "RMSE : 1.8179794690418578\n"
     ]
    }
   ],
   "source": [
    "def calc_trust_based_mean_rating(u, i, alpha, beta, sigma, user2item, item2user):\n",
    "    \"\"\"\n",
    "    Calculate trust-based mean rating on test set\n",
    "    \"\"\"\n",
    "    # Get all users who have rated item\n",
    "    users_and_ratings = [tup for tup in item2user[i]]\n",
    "    \n",
    "    # For each user, calculate trust with test user u\n",
    "    sum_of_num = 0.0\n",
    "    sum_of_den = 0.0\n",
    "    for user_and_rating in users_and_ratings:\n",
    "        trust_uv = compute_implicit_trust(u, user_and_rating[0], alpha, beta, sigma, user2item, item2user)\n",
    "        sum_of_num = sum_of_num + trust_uv * user_and_rating[1]\n",
    "        sum_of_den = sum_of_den + trust_uv\n",
    "    if sum_of_den == 0.0:\n",
    "        return 0.0\n",
    "    return sum_of_num / sum_of_den\n",
    "\n",
    "# Run inference on test set using trust-based mean rating\n",
    "run_inference_on_test_set(test_data, user2item, item2user, calc_trust_based_mean_rating, alpha, beta, sigma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 6.2 - Method 2 - Trust-based collaborative filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4088\n",
      "Item cold start count : 3268\n",
      "User cold start count : 18378\n",
      "Coverage : 0.11207061984264056\n",
      "Mean Absolute Error : 1.0613721153161506\n",
      "RMSE : 2.006375273520283\n"
     ]
    }
   ],
   "source": [
    "def calc_average_user_rating(u, user2item):\n",
    "    if not u in user2item:\n",
    "        return 0.0\n",
    "    return np.average([tup[1] for tup in user2item[u]])\n",
    "\n",
    "\n",
    "def calc_trust_based_collab_filtering(u, i, alpha, beta, sigma, user2item, item2user):\n",
    "    \"\"\"\n",
    "    Calculate trust-based collaborative filtering rating on test set\n",
    "    \"\"\"\n",
    "    # Get all users who have rated item\n",
    "    users_and_ratings = [tup for tup in item2user[i]]\n",
    "    \n",
    "    # For each user, calculate trust with test user u\n",
    "    sum_of_num = 0.0\n",
    "    sum_of_den = 0.0\n",
    "    for user_and_rating in users_and_ratings:\n",
    "        trust_uv = compute_implicit_trust(u, user_and_rating[0], alpha, beta, sigma, user2item, item2user)\n",
    "        sum_of_num = sum_of_num + trust_uv * (user_and_rating[1] - calc_average_user_rating(user_and_rating[0], user2item))\n",
    "        sum_of_den = sum_of_den + trust_uv\n",
    "    # Return 0 if no user has rated item\n",
    "    if sum_of_den == 0.0:\n",
    "        return 0.0\n",
    "    return calc_average_user_rating(u, user2item) + (sum_of_num/sum_of_den)\n",
    "\n",
    "# Run inference on test set using trust-based collaborative filtreing\n",
    "run_inference_on_test_set(test_data, user2item, item2user, calc_trust_based_collab_filtering, alpha, beta, sigma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 6.3 - Method 3 - Trust-filtered mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4088\n",
      "Item cold start count : 3268\n",
      "User cold start count : 18378\n",
      "Coverage : 0.11207061984264056\n",
      "Mean Absolute Error : 0.9376778610565589\n",
      "RMSE : 1.7134297967067953\n"
     ]
    }
   ],
   "source": [
    "def calc_trust_filtered_mean_rating(u, i, alpha, beta, sigma, user2item, item2user):\n",
    "    \"\"\"\n",
    "    Calculate trust-filterd mean rating on tst set. We filter for trust > 0\n",
    "    \"\"\"\n",
    "    # Get all users who have rated item\n",
    "    users_and_ratings = [tup for tup in item2user[i]]\n",
    "    \n",
    "    # For each user, calculate trust with test user u\n",
    "    sum_of_num = 0.0\n",
    "    trust_cnt = 0\n",
    "    for user_and_rating in users_and_ratings:\n",
    "        trust_uv = compute_implicit_trust(u, user_and_rating[0], alpha, beta, sigma, user2item, item2user)\n",
    "        if trust_uv > 0.0:\n",
    "            sum_of_num = sum_of_num + user_and_rating[1]\n",
    "            trust_cnt += 1\n",
    "    if trust_cnt == 0:\n",
    "        return 0.0\n",
    "    return sum_of_num / (1.0 * trust_cnt)\n",
    "\n",
    "# Run inference on test set using trust-filtered mean\n",
    "run_inference_on_test_set(test_data, user2item, item2user, calc_trust_filtered_mean_rating, alpha, beta, sigma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 7 - We notice that the coverage is low for the implicit approach. The reason for this that many users have only 1-2 ratings in the dataset. Thus, these users fall in the cold-start case\n",
    "\n",
    "# We now focus on filtering the dataset for users with >=4 items rated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of data points in original dataset tuples: 188477\n",
      "Number of data points in filtered dataset tuples: 54192\n"
     ]
    }
   ],
   "source": [
    "# Create a user2item dictionary over the entire dataset, and not just training set\n",
    "user2item_full = {}\n",
    "for data_tuple in dataset_tuples:\n",
    "    if data_tuple[1] in user2item_full:\n",
    "        user2item_full[data_tuple[1]].add((data_tuple[0], data_tuple[2]))\n",
    "    else:\n",
    "        itemrating = set()\n",
    "        itemrating.add((data_tuple[0], data_tuple[2]))\n",
    "        user2item_full[data_tuple[1]] = itemrating\n",
    "        \n",
    "filtered_dataset_tuples = [data_tuple for data_tuple in dataset_tuples if len(user2item_full[data_tuple[1]]) >= 4]\n",
    "\n",
    "print(\"Number of data points in original dataset tuples: {}\".format(len(dataset_tuples)))\n",
    "print(\"Number of data points in filtered dataset tuples: {}\".format(len(filtered_dataset_tuples)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 8 - Split filtered dataset in train/test using 80:20 split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of filtered training set: 43600\n",
      "Length of filtered test set: 10592\n"
     ]
    }
   ],
   "source": [
    "# Randomly shuffle dataset with fixed seed. Then split into train/test using 80:20 ratio\n",
    "random.Random(4).shuffle(filtered_dataset_tuples)\n",
    "filtered_train_data = filtered_dataset_tuples[:43600]\n",
    "filtered_test_data = filtered_dataset_tuples[43600:]\n",
    "\n",
    "# Print length of train and test dataset\n",
    "print(\"Length of filtered training set: {}\".format(len(filtered_train_data)))\n",
    "print(\"Length of filtered test set: {}\".format(len(filtered_test_data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 9 - Construct user2item and item2user dictionaries from filtered training data. Also, retain rating for each value in both dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of entries in filtered_user2item: 7444\n",
      "Total number of entries in filtered_item2user: 23985\n",
      "Printing 5 random entries in filtered_user2item.. \n",
      "jenmuse\n",
      "{('pr-Evenflo_Snugli_Comfort_Vent_Carrier_Baby_Carrier', 5), ('Elmer_s_Go_Paint', 5), ('Tek_Nek_Toys_Play_Learn_II_with_Hat_Assortment', 5), ('Aqua_Leisure_SunSmart_Hideaway_Pool', 5), ('Step_2_Frog_Sand_Box', 5), ('pr-Graco_Car_Seat_Base_8403', 5), ('Battat_Parents_Magazine_Record_A_Voice_Cell_Phone', 5), ('Cozy_Coupe_II_Car', 5), ('Playskool_Step_Start_Walk_N_Ride', 3), ('Illco_Sesame_Street_Musical_Lights_Phone', 1), ('Cosco_Alpha_Omega_Elite_Hammer_Print', 5), ('pr-Graco_LiteRider_7320', 5), ('Fisher_Price_Laugh_Learn_Learning_Table_32724820', 5), ('Kids_II_Baby_Einstein_Discovering_Water_Rocker_Seat', 4), ('Fisher_Price_Laugh_and_Learn_Learning_Piggy_Bank', 5)}\n",
      "apapage\n",
      "{('Hasbro_VCamNow_Camcorder', 1), ('2003_Nissan_Pathfinder', 1), ('Hewlett_Packard_7210_OfficeJet_All_In_One_Printer_2', 3), ('Palm_Palm_m105_Handheld__PDAs_P80701U', 1)}\n",
      "livefire\n",
      "{('SanDisk_Sansa_e250_2_GB_MP3_Player', 5), ('pr-Kodak_EasyShare_DX4530_Digital_Camera', 4), ('NetGear_SUPER_G_WLS_RRTR_SECURITY_ED_W_TREND_NTWK_SEC_1U_WGT624SCNA_Firewall', 2), ('Viewsonic_VE500_17___15__Viewable__LCD_Display__CRT_Monitors_VE500', 5), ('pr-HP_OfficeJet_7110_Printer', 2), ('pr-Kenmore_34720_Upright_Vacuum', 3), ('D_Link_DIR_628_RangeBooster_N_Dual_Band_Router_with_4_Port_10_100_Switch_2_Antennas_and_Dual_Band_D', 5)}\n",
      "audmac916\n",
      "{('Evenflo_Aura_Select_Travel_System_Georgia_Stripe_Stroller', 1), ('Evenflo_Tribute_5_DLX_Car_Seat', 5), ('GE_PDW7380NSS_Stainless_Steel_Dishwasher', 3), ('pr-Graco_DuoGlider_Tandem_Gingham', 4), ('Panasonic_TH_50PX75U_Television', 5), ('Little_Tikes_Totsports_Easy_Score_Basketball_Set', 3), ('hmgd_Indoor_Grills-George_Foreman-Lean_Mean_Fat_Reducing_Grilling_Machine_GR30', 4)}\n",
      "dkaakd\n",
      "{('pr-Apple_iPod_10GB_MAC_PC-M8976LL_A_MP3_Player', 5), ('Canon_EOS_400D_Twin_Lens_Kit_Silver_Body_18_55mm_EF_75_300mm_f_4_5_6_Lens_Digital_Camera', 5), ('Compaq_Ipaq_3835_pocket_PC_64MB_retail__PDAs___Handhelds_230397_002', 5), ('pr-Canon_Elura_60_Mini_DV_Digital_Camcorder', 5), ('Hewlett_Packard_HEWQ5987A_Color_LaserJet_Prntr_64MB_17_PPM_15_7_10_x17_7_10_x15_7_10_Printer', 2), ('2007_Audi_A4', 5), ('pr-Canon_Elura_70_Camcorder', 5), ('Panasonic_Lumix_DMC_TS1_DMC_FT1_Digital_Camera', 5), ('Nikon_Coolpix_4500_Cameras', 5), ('auto_Make-1997_Mitsubishi_Montero_Sport', 3), ('pr-Digital_Video_Recorders_TiVo_Series2_DVR_PVR_R240080', 4), ('auto_Make-2003_Honda_Odyssey', 5), ('pr-Mitsubishi_WS-55413_55_in_Rear_Projection_HDTV-Ready_Television', 4), ('auto_Make-2001_BMW_Z3', 5), ('2010_Mazda_CX_9_epi', 4), ('Palm_Treo_750v', 2), ('auto_Make-1995_Mazda_Millenia', 3)}\n"
     ]
    }
   ],
   "source": [
    "# Construct user2item from training data\n",
    "filtered_user2item = {}\n",
    "for data_tuple in filtered_train_data:\n",
    "    if data_tuple[1] in filtered_user2item:\n",
    "        filtered_user2item[data_tuple[1]].add((data_tuple[0], data_tuple[2]))\n",
    "    else:\n",
    "        itemrating = set()\n",
    "        itemrating.add((data_tuple[0], data_tuple[2]))\n",
    "        filtered_user2item[data_tuple[1]] = itemrating\n",
    "\n",
    "# Construct item2user from training data\n",
    "filtered_item2user = {}\n",
    "for data_tuple in filtered_train_data:\n",
    "    if data_tuple[0] in filtered_item2user:\n",
    "        filtered_item2user[data_tuple[0]].add((data_tuple[1], data_tuple[2]))\n",
    "    else:\n",
    "        userrating = set()\n",
    "        userrating.add((data_tuple[1], data_tuple[2]))\n",
    "        filtered_item2user[data_tuple[0]] = userrating\n",
    "        \n",
    "print(\"Total number of entries in filtered_user2item: {}\".format(len(filtered_user2item)))\n",
    "print(\"Total number of entries in filtered_item2user: {}\".format(len(filtered_item2user)))\n",
    "print(\"Printing 5 random entries in filtered_user2item.. \")\n",
    "for i, val in enumerate(itertools.islice(filtered_user2item, 5)):\n",
    "    print(val)\n",
    "    print(filtered_user2item[val])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 10 - Run inference using all 3 methods on the filtered dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running inference on filtered test set using trust-based mean rating\n",
      "2563\n",
      "Item cold start count : 3997\n",
      "User cold start count : 16\n",
      "Coverage : 0.2419750755287009\n",
      "Mean Absolute Error : 0.9219902285441315\n",
      "RMSE : 1.7278778049155208\n",
      "Running inference on filtered test set using trust-based collaborative filtering\n",
      "2563\n",
      "Item cold start count : 3997\n",
      "User cold start count : 16\n",
      "Coverage : 0.2419750755287009\n",
      "Mean Absolute Error : 0.9920943971783541\n",
      "RMSE : 1.7545552074832798\n",
      "Running inference on filtered test set using trust-filtered mean rating\n",
      "2563\n",
      "Item cold start count : 3997\n",
      "User cold start count : 16\n",
      "Coverage : 0.2419750755287009\n",
      "Mean Absolute Error : 0.9126201375247562\n",
      "RMSE : 1.642330271480556\n"
     ]
    }
   ],
   "source": [
    "# Run inference on test set using trust-based mean rating\n",
    "print(\"Running inference on filtered test set using trust-based mean rating\")\n",
    "run_inference_on_test_set(filtered_test_data, filtered_user2item, filtered_item2user, calc_trust_based_mean_rating, alpha, beta, sigma)\n",
    "\n",
    "# Run inference on test set using trust-based collaborative filtering\n",
    "print(\"Running inference on filtered test set using trust-based collaborative filtering\")\n",
    "run_inference_on_test_set(filtered_test_data, filtered_user2item, filtered_item2user, calc_trust_based_collab_filtering, alpha, beta, sigma)\n",
    "\n",
    "# Run inference on test set using trust-filtered mean\n",
    "print(\"Running inference on filtered test set using trust-filtered mean rating\")\n",
    "run_inference_on_test_set(filtered_test_data, filtered_user2item, filtered_item2user, calc_trust_filtered_mean_rating, alpha, beta, sigma)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
